{"cells":[{"cell_type":"markdown","source":["You should remove the `raise` exceptions below and insert your code in their place. The cells which say `DO NOT CHANGE THE CONTENT OF THIS CELL` are there to help you, if they fail, it's probably an indication of the fact that your code is wrong. You should not change their content - if you change them to make them correspond to what your program is producing, you will still not get the marks.\n\nIf you encounter an error while running your notebook that doesn't appear to be connected to RDDs (such as missing `imp`), you should check that you've run the initialization cells since you've started your latest cluster.\n\nBefore you turn your solution in, make sure everything runs as expected. With an attached cluster, you should **Clear State and Results** (under the **Clear** dropdown menu) and then click on the **Run all** icon. This runs all cells in the notebook from new. You should only submit this notebook if all cells run.\n\nThis homework is to be completed on your own. By the act of following these instructions and handing your work in, it is deemed that you have read and understand the rules on plagiarism as written in your student handbook."],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"advice","locked":true,"solution":false,"checksum":"0d6114a510fa3eff84cc1bb2cda180e2","grade":false,"cell_type":"markdown"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b74d847c-5bc6-4fa8-b476-6acb3405f049"}}},{"cell_type":"markdown","source":["We will use the historical World cup player dataset (the second cell of this notebook downloads this for you) which is in JSON format. The first two cells set the environment up for you, including downloading the file. The initial dataframe is also created for you, so your work starts when you start exploring the data in the three ways we have seen in lectures."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3c411971-b3e5-4c6b-8fa7-f4bd5fe51d35"}}},{"cell_type":"code","source":["# DO NOT CHANGE THE CONTENT OF THIS CELL\nimport imp\n\ntry:\n    imp.find_module('dbutils')\nexcept ImportError:\n    import pyspark\n    sc = pyspark.SparkContext()\n    from pyspark.sql import SQLContext\n    spark = SQLContext(sc)"],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"setup-pyspark","locked":true,"solution":false,"checksum":"746178fbae510fcdfd8fe3146559cd86","grade":false,"cell_type":"code"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3d1e9883-bfc6-4750-b90f-c81fdfff4d65"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# DO NOT CHANGE THE CONTENT OF THIS CELL\nimport urllib.request\n\ndef file_exists(path):\n    try:\n        dbutils.fs.ls(path)\n        return True\n    except Exception as e:\n        if 'java.io.FileNotFoundException' in str(e):\n            return False\n        else:\n            raise\n\nplayer_json = \"/FileStore/all-world-cup-players.json\"\n\ntry:\n    imp.find_module('dbutils')\n    if not file_exists(player_json) == True:\n        # Download to local /tmp\n        urllib.request.urlretrieve(\"https://github.com/jokecamp/FootballData/raw/master/World%20Cups/all-world-cup-players.json\", \"/tmp/all-world-cup-players.json\")\n        dbutils.fs.cp(\"file:/tmp/all-world-cup-players.json\", player_json)\nexcept ImportError:\n    print(\"Are you running this on Databricks?\")"],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"setup-file","locked":true,"solution":false,"checksum":"2da15815c7bc67a6c97d7cbe4266e36b","grade":false,"cell_type":"code"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"502634fa-fdae-4588-91c7-37d0a8c0ff27"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["The cell below reads the data into a dataframe named `playersDF`. If you look at the file, you'll see that it's not formed quite as Spark expects: it doesn't have a single line per json record. We therefore use the `multiline` option."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"82197f13-6712-4a27-90d6-13a23743ef7e"}}},{"cell_type":"code","source":["# DO NOT CHANGE THE CONTENT OF THIS CELL\nplayersDF = spark.read.option(\"multiline\",\"true\").json(player_json)\nassert playersDF.count() == 9443, \"Something has gone wrong with the reading process\""],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"setup-df","locked":true,"solution":false,"checksum":"615c5556fd6aeab04e835fafaf8b7d27","grade":false,"cell_type":"code"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8b1cf23d-8100-4fc1-af1b-61491f7179a0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["We will now explore three different ways to extract the same information from the data. \n1. Via DataFrames directly\n2. Via Views\n3. Via RDDs\n\nLet's start with the DataFrames. Use DataFrame operations to create a `teamNamesFromDF` DataFrame which contains all the team names from 2014 (only). (You may want to look at the DataFrame you have read in first.) The team names should only appear once in your resulting dataframe."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5e354814-a45c-47e3-9d77-1e0de5e3e6f7"}}},{"cell_type":"code","source":["#playersDF.show()\nteamNamesFromDF=playersDF.select('Team').where(playersDF.Year.like('2014')).distinct()\nteamNamesFromDF.show()"],"metadata":{"deletable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"teamNamesFromDF","locked":false,"solution":true,"checksum":"e770b3adabadec6fdbfdfa8f1bb39e5d","grade":false,"cell_type":"code"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c7cf5079-8d1f-4ac1-b510-8d1c19a495b5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-----------+\n|       Team|\n+-----------+\n|Ivory Coast|\n|     France|\n|     Greece|\n|  Argentina|\n|    Ecuador|\n|      Chile|\n|    Croatia|\n|      Italy|\n|      Spain|\n|    Uruguay|\n|     Mexico|\n|   Honduras|\n|Switzerland|\n|     Brazil|\n|      Japan|\n|    England|\n|   Cameroon|\n|  Australia|\n| Costa Rica|\n|   Colombia|\n+-----------+\nonly showing top 20 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------+\n       Team|\n+-----------+\nIvory Coast|\n     France|\n     Greece|\n  Argentina|\n    Ecuador|\n      Chile|\n    Croatia|\n      Italy|\n      Spain|\n    Uruguay|\n     Mexico|\n   Honduras|\nSwitzerland|\n     Brazil|\n      Japan|\n    England|\n   Cameroon|\n  Australia|\n Costa Rica|\n   Colombia|\n+-----------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# DO NOT CHANGE THE CONTENT OF THIS CELL\nfrom pyspark.sql import DataFrame\nassert isinstance(teamNamesFromDF, DataFrame), \"Your answer should be a dataframe\"\nassert teamNamesFromDF.count() == 32, \"Unexpected number of teams\""],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"test_teamNamesFromDF","locked":true,"solution":false,"points":2,"checksum":"72ae43c72c61b37780a8c39691e7d703","grade":true,"cell_type":"code"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7fa9c2ff-4356-4957-bdf4-9ffec4592d35"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Now do the same via constructing a temporary view called `players` from the data (remember that you'll need to ensure that the program doesn't fail if you run it twice - i.e. if the view already exists), using a Spark sql query to extract the 2014 team names (without repeats), and naming the resulting DataFrame `teamNamesFromTable`."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8aa3cecc-09e5-4d2d-b288-a25b11fe96aa"}}},{"cell_type":"code","source":["playersDF.createOrReplaceTempView(\"players\")\nteamNamesFromTable=spark.sql(\"SELECT Team FROM players WHERE Year LIKE '2014'\").distinct()\nteamNamesFromTable.show()"],"metadata":{"deletable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"teamNamesFromTable","locked":false,"solution":true,"checksum":"9bea159a3cf62dba56cf3b4dda003ab3","grade":false,"cell_type":"code"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3af5de31-0377-40d1-bd8b-83c7c90546f4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-----------+\n|       Team|\n+-----------+\n|Ivory Coast|\n|     France|\n|     Greece|\n|  Argentina|\n|    Ecuador|\n|      Chile|\n|    Croatia|\n|      Italy|\n|      Spain|\n|    Uruguay|\n|     Mexico|\n|   Honduras|\n|Switzerland|\n|     Brazil|\n|      Japan|\n|    England|\n|   Cameroon|\n|  Australia|\n| Costa Rica|\n|   Colombia|\n+-----------+\nonly showing top 20 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------+\n       Team|\n+-----------+\nIvory Coast|\n     France|\n     Greece|\n  Argentina|\n    Ecuador|\n      Chile|\n    Croatia|\n      Italy|\n      Spain|\n    Uruguay|\n     Mexico|\n   Honduras|\nSwitzerland|\n     Brazil|\n      Japan|\n    England|\n   Cameroon|\n  Australia|\n Costa Rica|\n   Colombia|\n+-----------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# DO NOT CHANGE THE CONTENT OF THIS CELL\n# Check the table was created\ntry:\n    imp.find_module('dbutils')\n    tableList = [t.name for t in spark.catalog.listTables()]\n    assert \"players\" in tableList, \"You have either not created your table or you have named it something other than players\"\nexcept:\n    assert ('players' in spark.tableNames()), \"You have either not created your table or you have named it something other than players\"\n    \nassert teamNamesFromTable.count() == 32, \"Unexpected number of teams\""],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"test_teamNamesFromTable","locked":true,"solution":false,"points":2,"checksum":"491ed1fc3af17cf6334ff4d1fa7bb4ea","grade":true,"cell_type":"code"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e2d69d03-fe2e-41f1-b181-f9f6c88d556a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Your third implementation should go via RDDs: i.e. you'll need to create a (Row) RDD from the DataFrame data, perform `.map`, `.filter` etc operations to obtain an RDD with the same result using RDDs. Your resulting RDD should be named `teamNamesFromRDD`."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"616c776d-951b-4456-9fc5-25537b4c5ba2"}}},{"cell_type":"code","source":["myRDD=playersDF.rdd\nteamNamesFromRDD=myRDD.map(lambda row: (row.Team,row.Year)).filter(lambda line: (line[1]==2014)).map(lambda fields: fields[0]).distinct()"],"metadata":{"deletable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"teamNamesFromRDD","locked":false,"solution":true,"checksum":"262d8c73a85627346e4a3f4ef83b0219","grade":false,"cell_type":"code"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e9cb6376-108e-45db-832d-2cb7e33a3a7c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# DO NOT CHANGE THE CONTENT OF THIS CELL\nfrom pyspark.rdd import RDD\nassert isinstance(teamNamesFromRDD, RDD), \"Your result should be an RDD\"\nassert teamNamesFromRDD.count() == 32, \"Unexpected number of teams\"\n\nlineage = teamNamesFromRDD.toDebugString()\nassert 'MapPartitionsRDD' in lineage.decode(), \"Did you really manage to answer this question via RDDs without a map?\""],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"test_teamNamesFromRDD","locked":true,"solution":false,"points":2,"checksum":"9da6655e818c829b41c49690dd7c3dff","grade":true,"cell_type":"code"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6d73e8af-5891-4cce-aa31-53d6e07f8d5c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9bc7f10f-3244-4b5b-a14d-c24c2db221cb"}},"outputs":[],"execution_count":0}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.7.6","nbconvert_exporter":"python","file_extension":".py"},"application/vnd.databricks.v1+notebook":{"notebookName":"spark_sql - Surekha","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":1455314374086050}},"nbformat":4,"nbformat_minor":0}
